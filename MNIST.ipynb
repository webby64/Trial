{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_datasets' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-af4c7f5a6f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#print(tfds.list_builders())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fashion_mnist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_supervised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#print(info)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_datasets' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(tfds.list_builders())\n",
    "dataset, info = tfds.load('fashion_mnist', as_supervised = True, with_info = True)\n",
    "dataset_test, dataset_train = dataset['test'], dataset['train']\n",
    "#print(info)\n",
    "def convert_types(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataset_train = dataset_train.map(convert_types).shuffle(10000).batch(batch_size)\n",
    "dataset_test = dataset_test.map(convert_types).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "print(\"Generator\")\n",
    "#datagen = ImageDataGenerator()\n",
    "datagen = ImageDataGenerator(rotation_range = 10, horizontal_flip = True, zoom_range = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(10,activation='softmax')\n",
    "# ])\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, BatchNormalization, Dropout, Activation, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class CNNModel(Model):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        drop_rate = 0.5\n",
    "        \n",
    "        self._layers = ([\n",
    "            Conv2D(32, 3), # 28, 28, 1 -> 26, 26, 32\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            Conv2D(64, 3), # 26, 26, 32 -> 24, 24, 64\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            MaxPool2D(), # 24, 24, 64 -> 12, 12, 64\n",
    "            Conv2D(128, 3), # 12, 12, 64 -> 10, 10, 128\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            Conv2D(256, 3), # 10, 10, 128 -> 8, 8, 256\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            MaxPool2D(), # 8, 8, 256 -> 4, 4, 256\n",
    "            Flatten(), # 4, 4, 256 -> 4096\n",
    "            Dense(256), # 4096 -> 256\n",
    "            BatchNormalization(),\n",
    "            Dropout(drop_rate),\n",
    "            Activation(tf.nn.relu),\n",
    "            Dense(10, activation = 'softmax') # 256 -> 10                        \n",
    "        ])                \n",
    "        \n",
    "    def call(self, x):\n",
    "        for layer in self._layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "       \n",
    "    \n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image)\n",
    "        loss = loss_object(label, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, predictions)\n",
    "        \n",
    "@tf.function\n",
    "def test_step(image, label):\n",
    "    predictions = model(image)\n",
    "    loss = loss_object(label, predictions)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4940635859966278, Accuracy: 81.6066665649414, Test Loss: 0.3473312258720398, Test Accuracy: 87.44000244140625, spent_time: 2.556767725944519 min\n",
      "Epoch 2, Loss: 0.4113214313983917, Accuracy: 84.74833679199219, Test Loss: 0.31387659907341003, Test Accuracy: 88.5, spent_time: 5.116659490267436 min\n",
      "Epoch 3, Loss: 0.3695756196975708, Accuracy: 86.29500579833984, Test Loss: 0.3014501631259918, Test Accuracy: 89.10333251953125, spent_time: 7.647784769535065 min\n",
      "Epoch 4, Loss: 0.3430013656616211, Accuracy: 87.30791473388672, Test Loss: 0.28941860795021057, Test Accuracy: 89.51499938964844, spent_time: 10.174489609400432 min\n",
      "Epoch 5, Loss: 0.32330355048179626, Accuracy: 88.03199768066406, Test Loss: 0.2830665409564972, Test Accuracy: 89.78400421142578, spent_time: 12.694288484255473 min\n",
      "Epoch 6, Loss: 0.3080766201019287, Accuracy: 88.58777618408203, Test Loss: 0.27736398577690125, Test Accuracy: 90.06000518798828, spent_time: 15.224726307392121 min\n",
      "Epoch 7, Loss: 0.295229971408844, Accuracy: 89.06452941894531, Test Loss: 0.2722964584827423, Test Accuracy: 90.29428100585938, spent_time: 17.785348665714263 min\n",
      "Epoch 8, Loss: 0.2844148576259613, Accuracy: 89.4472885131836, Test Loss: 0.26836535334587097, Test Accuracy: 90.50749969482422, spent_time: 20.348431011041004 min\n",
      "Epoch 9, Loss: 0.275012731552124, Accuracy: 89.8018569946289, Test Loss: 0.26553499698638916, Test Accuracy: 90.6611099243164, spent_time: 22.877793864409128 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epoch = 80\n",
    "start_time = time.time()\n",
    "\n",
    "#train_accuracies = []\n",
    "#test_accuracies = []\n",
    "train_accuracies_with_da = []\n",
    "test_accuracies_with_da = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):    \n",
    "    for image, label in dataset_train:\n",
    "        for _image, _label in datagen.flow(image, label, batch_size = batch_size):\n",
    "            train_step(_image, _label)\n",
    "            break\n",
    "        \n",
    "    for test_image, test_label in dataset_test:\n",
    "        test_step(test_image, test_label)\n",
    "        \n",
    "    #train_accuracies.append(train_accuracy.result())\n",
    "    #test_accuracies.append(test_accuracy.result())\n",
    "    train_accuracies_with_da.append(train_accuracy.result())\n",
    "    test_accuracies_with_da.append(test_accuracy.result())\n",
    "    \n",
    "    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}, spent_time: {} min'\n",
    "    spent_time = time.time() - start_time\n",
    "    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(), test_accuracy.result() * 100, spent_time / 60))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracies, label = 'Train Accuracy')\n",
    "plt.plot(test_accuracies, linestyle = 'dashed', label = 'Test Accuracy')\n",
    "plt.plot(train_accuracies_with_da, label = 'Train Accuracy with Data Augmentation')\n",
    "plt.plot(test_accuracies_with_da, linestyle = 'dashed', label = 'Test Accuracy with Data Augmentation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.4 on Python 3.6 & CUDA 10.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
